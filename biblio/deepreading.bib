
@report{bangert2019,
  title = {Recommendations for {{Services}} in a {{FAIR}} Data Ecosystem},
  author = {Bangert, Daniel and Hermans, Emilie and van Horik, René and de Jong, Maaike and Koers, Hylke and Mokrane, Mustapha},
  options = {useprefix=true},
  date = {2019-12-19},
  institution = {{Zenodo}},
  doi = {10.5281/zenodo.3585742},
  abstract = {This report highlights common challenges and priorities, and proposes a set of initial recommendations on how existing data infrastructures can evolve and collaborate to provide services that support the implementation of the FAIR data principles, in particular in the context of building the European Open Science Cloud (EOSC). The report is an output of three workshops designed to explore, discuss and formulate such recommendations and is aimed at stakeholders in the scholarly world and particularly the EOSC Governance.},
  langid = {english},
  file = {files/39350/Bangert et al. - 2019 - Recommendations for Services in a FAIR data ecosys.pdf}
}

@book{books_2011,
  title = {Articles on {{Donald Knuth}}, {{Including}}: {{Literate Programming}}, {{MMIX}}, {{Tex}}, {{Metafont}}, {{Mix}}, {{Quater-Imaginary Base}}, {{Knuth}} "{{Morris}} "{{Pratt Algorithm}}, {{Knuth}}'s {{Up}}},
  shorttitle = {Articles on {{Donald Knuth}}, {{Including}}},
  author = {Books, Hephaestus},
  date = {2011-09-01},
  eprint = {SvoGywAACAAJ},
  eprinttype = {googlebooks},
  publisher = {{Hephaestus Books}},
  abstract = {Please note that the content of this book primarily consists of articles available from Wikipedia or other free sources online. Hephaestus Books represents a new publishing paradigm, allowing disparate content sources to be curated into cohesive, relevant, and informative books. To date, this content has been curated from Wikipedia articles and images under Creative Commons licensing, although as Hephaestus Books continues to increase in scope and dimension, more licensed and public domain content is being added. We believe books such as this represent a new and exciting lexicon in the sharing of human knowledge. This particular book is a collaboration focused on Donald Knuth.More info: Donald Ervin Knuth (born January 10, 1938) is a computer scientist and Professor Emeritus of the Art of Computer Programming at Stanford University.},
  isbn = {978-1-243-39959-5},
  langid = {english},
  pagetotal = {108},
  annotation = {00000}
}

@article{butterfield1958,
  title = {The {{Copernican Revolution}}: {{Planetary Astronomy}} in the {{Development}} of {{Western Thought}}},
  shorttitle = {The {{Copernican Revolution}}},
  author = {Butterfield, Herbert and Kuhn, Thomas S.},
  date = {1958-04},
  journaltitle = {The American Historical Review},
  shortjournal = {The American Historical Review},
  volume = {63},
  number = {3},
  pages = {656},
  issn = {00028762},
  doi = {10.2307/1848896},
  langid = {english},
  file = {files/41773/Butterfield und Kuhn - 1958 - The Copernican Revolution Planetary Astronomy in .pdf}
}

@article{corti,
  title = {Managing {{anD Sharing reSearch Data}}},
  author = {Corti, Louise},
  pages = {8},
  langid = {english},
  file = {files/39316/Corti - Managing anD Sharing reSearch Data.pdf}
}

@article{Gerd_Grashoff2016-oi,
  title = {Ancient Sundials},
  author = {{Gerd Graßhoff} and {Elisabeth Rinner} and {Karlheinz Schaldach} and {Bernhard Fritsch} and {Liba Taub}},
  date = {2016},
  publisher = {{Edition Topoi}}
}

@article{Gerd_Grashoff2016-pg,
  title = {Digital Pantheon},
  author = {{Gerd Graßhoff} and {Markus Wäfler} and {Michael Heinzelmann} and {Christian Berndt} and {Jon Albers} and {Oskar Kaelin} and {Bernd Kulawik} and {Ralph Rosenbauer} and {Nikolaos Theocharis} and {Michael Lustenberger} and {Bernhard Fritsch}},
  date = {2016},
  publisher = {{Edition Topoi}}
}

@dataset{gerd_grasshoff_2019_3577203,
  title = {Ancient Conical Sundial Measurements},
  author = {Graßhoff, Gerd and Kotschka, Florian},
  date = {2019-12},
  publisher = {{Zenodo}},
  doi = {10.5281/zenodo.3577203}
}

@dataset{gerd_grasshoff_2021_4545677,
  title = {Data of Ancient Greek Parapegmata},
  author = {Graßhoff, Gerd and Kotschka, Florian and Taub, Liba and Rinner, Elisabeth and Sum, Jessica},
  date = {2021-02},
  publisher = {{Zenodo}},
  doi = {10.5281/zenodo.4545677},
  version = {1},
  file = {files/41719/Graßhoff et al_2021_Data of ancient greek parapegmata.pdf}
}

@incollection{Grashoff_Gerd2017-es,
  title = {Living According to the Seasons - the Power of Parapegmata},
  booktitle = {Knowledge, Text and Practice in Ancient Technical Writing},
  author = {{Graßhoff, Gerd}},
  editor = {Formisano, Marco and van der Eijk, Philip},
  options = {useprefix=true},
  date = {2017},
  pages = {200--216},
  publisher = {{Cambridge University Press}},
  location = {{Cambridge}}
}

@incollection{Grashoff2018-bz,
  title = {Innovationen Der Zeit: {{Evolution}} Antiker Sonnenuhren},
  booktitle = {Innovationen Der Antike},
  author = {Graßhoff, Gerd},
  date = {2018},
  edition = {1},
  pages = {96--107},
  publisher = {{Verlag Philipp Zabern}},
  location = {{Darmstadt}}
}

@dataset{grasshoff2021a,
  title = {Text Corpus of {{Kepler}}'s {{Astronomia}} Nova},
  author = {Graßhoff, Gerd and Yeghaneh Abkenar, Mohammad},
  date = {2021-04-16},
  publisher = {{Zenodo}},
  doi = {10.5281/ZENODO.4696891},
  abstract = {The JSON file contains preprocessed paragraphs of Kepler’s Astronomia Nova for machine learning. The database is derived from Donahue’s translation: Kepler, Johannes, New Astronomy, rev. edition, tr. by William H. Donahue, Green Lion Press, 2015. The text was digitized using OCR and automated text processing aiming at “pure” text containing machine-readable sentences in UTF8. Special characters, reference marks, and other markings were removed. OCR artefacts and errors may remain. For the authoritative text see Donahue’s edition. Digital Latin version cf. Kepler’s Gesammelte Werke.}
}

@article{gray,
  title = {Data {{Repositories}} and {{Data Catalogues}}},
  author = {Gray, Stephen},
  pages = {4},
  langid = {english},
  file = {files/39313/Gray - Data Repositories and Data Catalogues.pdf}
}

@incollection{khot2018,
  title = {{{SciTail}}: {{A Textual Entailment Dataset}} from {{Science Question Answering}}},
  booktitle = {{{AAAI}}},
  author = {Khot, Tushar and Sabharwal, Ashish and Clark, Peter},
  date = {2018},
  pages = {9},
  abstract = {We present a new dataset and model for textual entailment, derived from treating multiple-choice question-answering as an entailment problem. SCITAIL is the first entailment set that is created solely from natural sentences that already exist independently “in the wild” rather than sentences authored specifically for the entailment task. Different from existing entailment datasets, we create hypotheses from science questions and the corresponding answer candidates, and premises from relevant web sentences retrieved from a large corpus. These sentences are often linguistically challenging. This, combined with the high lexical similarity of premise and hypothesis for both entailed and non-entailed pairs, makes this new entailment task particularly difficult. The resulting challenge is evidenced by state-of-the-art textual entailment systems achieving mediocre performance on SCITAIL, especially in comparison to a simple majority class baseline. As a step forward, we demonstrate that one can improve accuracy on SCITAIL by 5\% using a new neural model that exploits linguistic structure.},
  langid = {english},
  file = {files/38345/Khot et al. - SciTail A Textual Entailment Dataset from Science.pdf}
}

@article{knuth1984,
  title = {Literate {{Programming}}},
  author = {Knuth, D. E.},
  date = {1984-01-01},
  journaltitle = {The Computer Journal},
  shortjournal = {Comput J},
  volume = {27},
  number = {2},
  pages = {97--111},
  publisher = {{Oxford Academic}},
  issn = {0010-4620},
  doi = {10.1093/comjnl/27.2.97},
  abstract = {Abstract.  The author and his associates have been experimenting for the past several years with a programming language and documentation system called WEB. Thi},
  langid = {english},
  file = {files/39295/Knuth - 1984 - Literate Programming.pdf;files/39294/343244.html}
}

@book{kuhn2012,
  title = {The Structure of Scientific Revolutions},
  author = {Kuhn, Thomas S. and Hacking, Ian},
  date = {2012},
  edition = {Fourth edition},
  publisher = {{The University of Chicago Press}},
  location = {{Chicago ; London}},
  isbn = {978-0-226-45811-3 978-0-226-45812-0},
  langid = {english},
  pagetotal = {217},
  file = {files/41774/Kuhn und Hacking - 2012 - The structure of scientific revolutions.pdf}
}

@article{tolle2018,
  title = {{{SEMANTIC SEARCH BASED ON NATURAL LANGUAGE PROCESSING}} – {{A NUMISMATIC EXAMPLE}}},
  author = {Tolle, Karsten and Klinger, Patricia and Gampe, Sebastian and Peter, Ulrike},
  date = {2018-09-12},
  journaltitle = {JOURNAL OF ANCIENT HISTORY AND ARCHAEOLOGY},
  volume = {5},
  number = {3},
  issn = {2360-266X},
  doi = {10.14795/j.v5i3.334},
  abstract = {Iconographic representations on ancient artifacts are described in many existing databases and literature as human readable text. We applied Natural Language Processing (NLP) approaches in order to extract the semantics out of these textual descriptions and in this way enable semantic searches over them. This allows more sophisticated requests compared to the common existing keyword searches. As we show in our experiments based on numismatic datasets, the approach is generic in the sense that once the system is trained on one dataset, it can be applied without any further manual work also to datasets that have similar content. Of course, additional adaptions would further improve the results. Since the approach requires manual work only during the training phase, it can easily be applied to huge datasets without manual work and therefore without major extra costs. In fact, in our experience bigger datasets generate even better results because there is more data for training. Since our approach is not bound to a certain domain and the numismatic datasets are just an example, it could serve as a blueprint for many other areas. It could also help to build bridges between disciplines since textual iconographic descriptions are to be found also for pottery, sculpture and elsewhere.},
  langid = {english},
  file = {files/38304/Tolle et al. - 2018 - SEMANTIC SEARCH BASED ON NATURAL LANGUAGE PROCESSI.pdf;files/38305/334.html}
}

@article{wilkinson2017,
  title = {Interoperability and {{FAIRness}} through a Novel Combination of {{Web}} Technologies},
  author = {Wilkinson, Mark D. and Verborgh, Ruben and Santos, Luiz Olavo Bonino da Silva and Clark, Tim and Swertz, Morris A. and Kelpin, Fleur D. L. and Gray, Alasdair J. G. and Schultes, Erik A. and van Mulligen, Erik M. and Ciccarese, Paolo and Kuzniar, Arnold and Gavai, Anand and Thompson, Mark and Kaliyaperumal, Rajaram and Bolleman, Jerven T. and Dumontier, Michel},
  date = {2017-04-24},
  journaltitle = {PeerJ Computer Science},
  shortjournal = {PeerJ Comput. Sci.},
  volume = {3},
  pages = {e110},
  publisher = {{PeerJ Inc.}},
  issn = {2376-5992},
  doi = {10.7717/peerj-cs.110},
  abstract = {Data in the life sciences are extremely diverse and are stored in a broad spectrum of repositories ranging from those designed for particular data types (such as KEGG for pathway data or UniProt for protein data) to those that are general-purpose (such as FigShare, Zenodo, Dataverse or EUDAT). These data have widely different levels of sensitivity and security considerations. For example, clinical observations about genetic mutations in patients are highly sensitive, while observations of species diversity are generally not. The lack of uniformity in data models from one repository to another, and in the richness and availability of metadata descriptions, makes integration and analysis of these data a manual, time-consuming task with no scalability. Here we explore a set of resource-oriented Web design patterns for data discovery, accessibility, transformation, and integration that can be implemented by any general- or special-purpose repository as a means to assist users in finding and reusing their data holdings. We show that by using off-the-shelf technologies, interoperability can be achieved atthe level of an individual spreadsheet cell. We note that the behaviours of this architecture compare favourably to the desiderata defined by the FAIR Data Principles, and can therefore represent an exemplar implementation of those principles. The proposed interoperability design patterns may be used to improve discovery and integration of both new and legacy data, maximizing the utility of all scholarly outputs.},
  langid = {english},
  file = {files/39300/Wilkinson et al. - 2017 - Interoperability and FAIRness through a novel comb.pdf;files/39299/cs-110.html}
}


